{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Reddit API and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previous:** [Data Cleaning and EDA](./02_data_cleaning_and_eda.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#NLTK\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "#Scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, recall_score, precision_score, balanced_accuracy_score, zero_one_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing stage\n",
    "In this stage, we will take the clean data and segregate them into train and test data. We will be using ```train_test_split``` to segregate them and our test data size is set at 20%.\n",
    "\n",
    "The **train data** `(train_title & train_subreddit)` will further undergo a round of ```train_test_split``` to create our validation set `(X_train, X_test, y_train, y_test)` which will aid us in testing various models to find the model that best generalizes. \n",
    "\n",
    "The **test data** `(test_title & test_subreddit)` will remain to be our \"unseen data\", which will test the sucess of our final model selected.\n",
    "\n",
    "\n",
    "These data will then undergo feature extraction (or vectorization) such as `CountVectorizer`, as the words need to be encoded as integers or floating point values for use as input to machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create an unseen data \n",
    "In order to test if the model is successful, we shall create a set of unseen data (test set). This will check how well our data generalizes to the unseen data.\n",
    "\n",
    "Since the trend in technology changes with time, we will take a randomized sample of 20% of the dataset as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['subreddit']\n",
    "\n",
    "train_title, test_title, train_subreddit, test_subreddit = train_test_split(X,\n",
    "                                                                            y,\n",
    "                                                                            stratify=y,\n",
    "                                                                            random_state=42,\n",
    "                                                                            test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unseen_df = pd.DataFrame(data=[test_subreddit, test_title]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export unseen data to csv.\n",
    "unseen_df.to_csv('../datasets/unseen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create validation set\n",
    "This set will help us model evaluation and hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_title,\n",
    "                                                    train_subreddit,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319    target ad placeholders reference upcoming new ...\n",
       "26      product video designed speed helpfulness googl...\n",
       "674     xiaomi mi mix solidifies status bona fide work...\n",
       "355              samsung galaxy z fold review future flat\n",
       "1458                           shortcuts sunday september\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview X_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data=[y_train, X_train]).T\n",
    "test_df = pd.DataFrame(data=[y_test, X_test]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export validation set to csv.\n",
    "train_df.to_csv('../datasets/train.csv', index=False)\n",
    "train_df.to_csv('../datasets/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Extraction: Vectorize our text data\n",
    "In order to pass the text features into our model, we need to transform the title strings into a matrix of word (i.e.token) counts. \n",
    "\n",
    "\n",
    "The ```CountVectorizer``` create columns (also known as vectors), where each column counts how many times each word is observed in each title string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our CountVectorizer.\n",
    "cvec = CountVectorizer()\n",
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                          columns = cvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                         columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train set has 2689 features after CountVectorizer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abrams</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>access</th>\n",
       "      <th>accessories</th>\n",
       "      <th>accessory</th>\n",
       "      <th>according</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>...</th>\n",
       "      <th>ysk</th>\n",
       "      <th>yuzu</th>\n",
       "      <th>zach</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zenfone</th>\n",
       "      <th>zigbee</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zte</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  abrams  absolutely  accelerate  access  accessories  \\\n",
       "0        0     0       0           0           0       0            0   \n",
       "1        0     0       0           0           0       0            0   \n",
       "2        0     0       0           0           0       0            0   \n",
       "3        0     0       0           0           0       0            0   \n",
       "4        0     0       0           0           0       0            0   \n",
       "\n",
       "   accessory  according  accordingly  ...  ysk  yuzu  zach  zdnet  zenfone  \\\n",
       "0          0          0            0  ...    0     0     0      0        0   \n",
       "1          0          0            0  ...    0     0     0      0        0   \n",
       "2          0          0            0  ...    0     0     0      0        0   \n",
       "3          0          0            0  ...    0     0     0      0        0   \n",
       "4          0          0            0  ...    0     0     0      0        0   \n",
       "\n",
       "   zigbee  zones  zoom  zte  zuckerberg  \n",
       "0       0      0     0    0           0  \n",
       "1       0      0     0    0           0  \n",
       "2       0      0     0    0           0  \n",
       "3       0      0     0    0           0  \n",
       "4       0      0     0    0           0  \n",
       "\n",
       "[5 rows x 2689 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\" X_train set has {X_train_cvec.shape[1]} features after CountVectorizer\")\n",
    "X_train_cvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 2689)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ios</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>android</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iphone</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>watch</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>samsung</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pixel</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>support</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pro</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>galaxy</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phone</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ipad</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>review</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thread</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>september</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>widgets</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>first</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word count\n",
       "0       apple   244\n",
       "1         app   122\n",
       "2         ios   107\n",
       "3     android   105\n",
       "4         new   100\n",
       "5      google    90\n",
       "6      iphone    63\n",
       "7       watch    61\n",
       "8     samsung    57\n",
       "9       pixel    56\n",
       "10    support    56\n",
       "11        pro    52\n",
       "12     galaxy    52\n",
       "13      phone    49\n",
       "14       ipad    43\n",
       "15     review    40\n",
       "16     thread    39\n",
       "17  september    39\n",
       "18    widgets    37\n",
       "19      first    34"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of frequency of some top features\n",
    "top20feat = X_train_cvec.sum().sort_values(ascending=False).head(20).index.tolist()\n",
    "top20featcount = X_train_cvec.sum().sort_values(ascending=False).head(20).values.tolist()\n",
    "df_top20 = pd.DataFrame(data=[top20feat, top20featcount], index=['word', 'count']).T\n",
    "df_top20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Our data has been processed above, it is now ready for modelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "Baseline accuracy which is the percentage of the majority class, regardless of whether it is 1 or 0. \n",
    "This serves as the benchmark for our models to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.533461\n",
       "0    0.466539\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check baseline accuracy\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model\n",
    "Now that our data is ready to be fed into the model, lets try fitting into our first model, a Naive Bayes model. \n",
    "\n",
    "In the X_train set above, the columns are all integer counts, so MultunomialNB is the best choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#1. Instantiate model\n",
    "nb_c = MultinomialNB()\n",
    "\n",
    "#2. Fit our model\n",
    "nb_c_model = nb_c.fit(X_train_cvec, y_train)\n",
    "\n",
    "#3. Generate our predictions\n",
    "nb_c_pred = nb_c_model.predict(X_test_cvec)\n",
    "#   probabilities of predicting 1\n",
    "nb_c_proba_1 = [i[1] for i in nb_c_model.predict_proba(X_test_cvec)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define function to print scores:\n",
    "def model_score(estimator, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #mean cross val score on train model\n",
    "    mean_cv_score = round(cross_val_score(estimator, X_train, y_train, cv=5).mean(),4)\n",
    "    \n",
    "    #score our model on the training and test set\n",
    "    train_score = round(estimator.score(X_train, y_train),4)\n",
    "    test_score = round(estimator.score(X_test, y_test),4)\n",
    "    \n",
    "    #print model scores\n",
    "    print(f\"Cross val score on train model: {mean_cv_score}\")\n",
    "    print(f\"Accuracy score on train model: {train_score}\")\n",
    "    print(f\"Accuracy score on test model: {test_score}\")\n",
    "    \n",
    "    return mean_cv_score, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score on train model: 0.9373\n",
      "Accuracy score on train model: 0.9862\n",
      "Accuracy score on test model: 0.9331\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score, train_score, test_score = model_score(nb_c_model, X_train_cvec, y_train, X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to print performance metrics\n",
    "def perf_metrics(y_true, y_pred, y_proba):\n",
    "    \n",
    "    #Generate a confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # print categories\n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"True Positives: %s\" % tp)\n",
    "    \n",
    "    #compute metrics\n",
    "    bal_accuracy = round(balanced_accuracy_score(y_true, y_pred),4)\n",
    "    misclassification = round(zero_one_loss(y_true, y_pred),4)\n",
    "    specificity = round(recall_score(y_true, y_pred, pos_label=0),4)\n",
    "    sensitivity = round(recall_score(y_true, y_pred, pos_label=1),4)\n",
    "    precision = round(precision_score(y_true, y_pred),4)\n",
    "    roc_auc = round(roc_auc_score(y_true, y_proba),4)\n",
    "        \n",
    "    #print metrics\n",
    "    print(\"\\nPerformance metrics\\n--------------------\")\n",
    "    print(f'Balanced Accuracy: {bal_accuracy}')\n",
    "    print(f'Misclassification: {misclassification}')\n",
    "    print(f'Specificity: {specificity}')\n",
    "    print(f'Sensitivity: {sensitivity}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'ROC_AUC: {roc_auc} \\n')\n",
    "\n",
    "    #cross-check with classfication report\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    \n",
    "    return tn, fp, fn, tp, bal_accuracy, misclassification, specificity, sensitivity, precision, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 7\n",
      "True Positives: 163\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9308\n",
      "Misclassification: 0.0669\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9588\n",
      "Precision: 0.9209\n",
      "ROC_AUC: 0.9764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9489    0.9028    0.9253       144\n",
      "           1     0.9209    0.9588    0.9395       170\n",
      "\n",
      "    accuracy                         0.9331       314\n",
      "   macro avg     0.9349    0.9308    0.9324       314\n",
      "weighted avg     0.9337    0.9331    0.9330       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp, bal_accuracy, misclassification, specificity, sensitivity, precision, roc_auc = perf_metrics(\n",
    "    y_test, nb_c_pred, nb_c_proba_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store these scores into a list of dictionaries for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = {'model': 'nb',\n",
    "             'vectorizer': 'cvec',\n",
    "             'valid_train': train_score,\n",
    "             'valid_test': test_score,\n",
    "             'mean_cv': mean_cv_score,\n",
    "             'tn': tn,\n",
    "             'fp': fp,\n",
    "             'fn': fn,\n",
    "             'tp': tp,\n",
    "             'bal_accuracy': bal_accuracy,\n",
    "             'misclassification': misclassification,\n",
    "             'specificity': specificity,\n",
    "             'sensitivity': sensitivity,\n",
    "             'precision': precision,\n",
    "             'roc_auc' : roc_auc,\n",
    "             'params' : 'default'}\n",
    "\n",
    "scores = [dict_scores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "\n",
       "   roc_auc   params  \n",
       "0   0.9764  default  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview scores\n",
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the model is slightly overfit. If used as our final model, we can tune our hyperparameters to set limit to max_features which might decrease the overfit.\n",
    "\n",
    "#### Naive Bayes model + TfidfVectorizer\n",
    "\n",
    "Next, we will try a different Vectorizer: ```TfidfVectorizer``` and see which scores better.\n",
    "\n",
    "A Term Frequency-Inverse Document Frequency (TF-IDF) score tells us which words are most discriminating between \"documents\". Words that occur often in one \"document\" but don't occur in many \"documents\" contain a great deal of discriminating power.\n",
    "\n",
    "Simply put, the mechanism of the TfidfVectorizer is that: \n",
    "- Common words are penalized.\n",
    "- Rare words have more influence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Tfidf Vectorizer\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "# Fit our TfidfVectorizer on the training data and transform training data.\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train).toarray(),\n",
    "                          columns = tvec.get_feature_names())\n",
    "# Transform our testing data with the already-fit TfidfVectorizer.\n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test).toarray(),\n",
    "                         columns = tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train set has 2689 features after TfidfVectorizer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abrams</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>access</th>\n",
       "      <th>accessories</th>\n",
       "      <th>accessory</th>\n",
       "      <th>according</th>\n",
       "      <th>accordingly</th>\n",
       "      <th>...</th>\n",
       "      <th>ysk</th>\n",
       "      <th>yuzu</th>\n",
       "      <th>zach</th>\n",
       "      <th>zdnet</th>\n",
       "      <th>zenfone</th>\n",
       "      <th>zigbee</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zte</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941 rows × 2689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ability  able  abrams  absolutely  accelerate  access  accessories  \\\n",
       "0        0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "1        0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "2        0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "3        0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "4        0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "..       ...   ...     ...         ...         ...     ...          ...   \n",
       "936      0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "937      0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "938      0.0   0.0     0.0    0.476334         0.0     0.0          0.0   \n",
       "939      0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "940      0.0   0.0     0.0    0.000000         0.0     0.0          0.0   \n",
       "\n",
       "     accessory  according  accordingly  ...  ysk  yuzu  zach  zdnet  zenfone  \\\n",
       "0          0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "1          0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "2          0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "3          0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "4          0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "..         ...        ...          ...  ...  ...   ...   ...    ...      ...   \n",
       "936        0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "937        0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "938        0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "939        0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "940        0.0        0.0          0.0  ...  0.0   0.0   0.0    0.0      0.0   \n",
       "\n",
       "     zigbee  zones  zoom  zte  zuckerberg  \n",
       "0       0.0    0.0   0.0  0.0         0.0  \n",
       "1       0.0    0.0   0.0  0.0         0.0  \n",
       "2       0.0    0.0   0.0  0.0         0.0  \n",
       "3       0.0    0.0   0.0  0.0         0.0  \n",
       "4       0.0    0.0   0.0  0.0         0.0  \n",
       "..      ...    ...   ...  ...         ...  \n",
       "936     0.0    0.0   0.0  0.0         0.0  \n",
       "937     0.0    0.0   0.0  0.0         0.0  \n",
       "938     0.0    0.0   0.0  0.0         0.0  \n",
       "939     0.0    0.0   0.0  0.0         0.0  \n",
       "940     0.0    0.0   0.0  0.0         0.0  \n",
       "\n",
       "[941 rows x 2689 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of TfidfVectorized X_train\n",
    "print(f\" X_train set has {X_train_tvec.shape[1]} features after TfidfVectorizer\")\n",
    "X_train_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#1. Instantiate model\n",
    "nb_t = MultinomialNB()\n",
    "\n",
    "#2. Fit our model\n",
    "nb_t_model = nb_t.fit(X_train_tvec, y_train)\n",
    "\n",
    "#3. Generate our predictions\n",
    "nb_t_pred = nb_t_model.predict(X_test_tvec)\n",
    "#   probabilities of predicting 1\n",
    "nb_t_proba_1 = [i[1] for i in nb_t_model.predict_proba(X_test_cvec)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Naive Bayes model with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score on train model: 0.9235\n",
      "Accuracy score on train model: 0.9894\n",
      "Accuracy score on test model: 0.9204\n"
     ]
    }
   ],
   "source": [
    "#score our model on the training and test set\n",
    "mean_cv_score, train_score, test_score = model_score(nb_t, X_train_tvec, y_train, X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the model with TfidfVectorizer did not score as well as the model with CountVectorizer. We would still like to store the scores into the dictionary for reference. Since there are many steps to do so, we have defined a function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to run pipe with vectorizer and estimator\n",
    "# also stores scores into dictionary\n",
    "\n",
    "def run_pipe(pipe, X_train, X_test, y_train, y_test, dict_scores, params='default'):\n",
    "    \n",
    "    #fit pipeline\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Model = {pipe.get_params()['steps'][1][0]} with {pipe.get_params()['steps'][0][0]} \")\n",
    "    print(\"--------------------\\n\")\n",
    "    \n",
    "    #evaluate model\n",
    "    mean_cv_score, train_score, test_score = model_score(pipe, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"--------------------\\n\")\n",
    "    \n",
    "    #generate predictions\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    #generate probabilities of predicting 1\n",
    "    y_proba = [i[1] for i in pipe.predict_proba(X_test)]\n",
    "    \n",
    "    #compute metrics\n",
    "    tn, fp, fn, tp, bal_accuracy, misclassification, specificity, sensitivity, precision, roc_auc = perf_metrics(\n",
    "        y_test, y_pred, y_proba)\n",
    "    \n",
    "    #store scores into dictionary\n",
    "    dict_scores = {'model': pipe.get_params()['steps'][1][0],\n",
    "                 'vectorizer': pipe.get_params()['steps'][0][0],\n",
    "                 'valid_train': train_score,\n",
    "                 'valid_test': test_score,\n",
    "                 'mean_cv': mean_cv_score,\n",
    "                 'tn': tn,\n",
    "                 'fp': fp,\n",
    "                 'fn': fn,\n",
    "                 'tp': tp,\n",
    "                 'bal_accuracy': bal_accuracy,\n",
    "                 'misclassification': misclassification,\n",
    "                 'specificity': specificity,\n",
    "                 'sensitivity': sensitivity,\n",
    "                 'precision': precision,\n",
    "                 'roc_auc' :roc_auc,\n",
    "                 'params': params}\n",
    "    scores.append(dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = nb with tvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9256\n",
      "Accuracy score on train model: 0.9894\n",
      "Accuracy score on test model: 0.9204\n",
      "--------------------\n",
      "\n",
      "True Negatives: 124\n",
      "False Positives: 20\n",
      "False Negatives: 5\n",
      "True Positives: 165\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9158\n",
      "Misclassification: 0.0796\n",
      "Specificity: 0.8611\n",
      "Sensitivity: 0.9706\n",
      "Precision: 0.8919\n",
      "ROC_AUC: 0.9753 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9612    0.8611    0.9084       144\n",
      "           1     0.8919    0.9706    0.9296       170\n",
      "\n",
      "    accuracy                         0.9204       314\n",
      "   macro avg     0.9266    0.9158    0.9190       314\n",
      "weighted avg     0.9237    0.9204    0.9199       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create our pipeline\n",
    "pipe_tvec_nb = Pipeline([('tvec', TfidfVectorizer()),\n",
    "                         ('nb', MultinomialNB())])\n",
    "#call function:\n",
    "run_pipe(pipe_tvec_nb, X_train, X_test, y_train, y_test, dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>124</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "1    nb       tvec       0.9894      0.9204   0.9256  124  20   5  165   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "1        0.9158             0.0796       0.8611       0.9706     0.8919   \n",
       "\n",
       "   roc_auc   params  \n",
       "0   0.9764  default  \n",
       "1   0.9753  default  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview scores in a dataframe\n",
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Logistic Regression model\n",
    "In order to make a comparison, we shall try fitting to another classification model - Logistic Regression model.\n",
    "To streamline that process, lets fit them into pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit each model into pipeline\n",
    "pipe_cvec_lr = Pipeline([('cvec', CountVectorizer()),\n",
    "                  ('lr', LogisticRegression())])\n",
    "\n",
    "pipe_tvec_lr = Pipeline([('tvec', TfidfVectorizer()),\n",
    "                  ('lr', LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = lr with cvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9235\n",
      "Accuracy score on train model: 0.9968\n",
      "Accuracy score on test model: 0.914\n",
      "--------------------\n",
      "\n",
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 13\n",
      "True Positives: 157\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9132\n",
      "Misclassification: 0.086\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9235\n",
      "Precision: 0.9181\n",
      "ROC_AUC: 0.9783 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.9028    0.9059       144\n",
      "           1     0.9181    0.9235    0.9208       170\n",
      "\n",
      "    accuracy                         0.9140       314\n",
      "   macro avg     0.9136    0.9132    0.9134       314\n",
      "weighted avg     0.9140    0.9140    0.9140       314\n",
      "\n",
      "Model = lr with tvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9362\n",
      "Accuracy score on train model: 0.9872\n",
      "Accuracy score on test model: 0.9236\n",
      "--------------------\n",
      "\n",
      "True Negatives: 128\n",
      "False Positives: 16\n",
      "False Negatives: 8\n",
      "True Positives: 162\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9209\n",
      "Misclassification: 0.0764\n",
      "Specificity: 0.8889\n",
      "Sensitivity: 0.9529\n",
      "Precision: 0.9101\n",
      "ROC_AUC: 0.9826 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.8889    0.9143       144\n",
      "           1     0.9101    0.9529    0.9310       170\n",
      "\n",
      "    accuracy                         0.9236       314\n",
      "   macro avg     0.9256    0.9209    0.9227       314\n",
      "weighted avg     0.9244    0.9236    0.9234       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run the pipeline using our defined function\n",
    "run_pipe(pipe_cvec_lr, X_train, X_test, y_train, y_test, dict_scores)\n",
    "run_pipe(pipe_tvec_lr, X_train, X_test, y_train, y_test, dict_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>124</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "1    nb       tvec       0.9894      0.9204   0.9256  124  20   5  165   \n",
       "2    lr       cvec       0.9968      0.9140   0.9235  130  14  13  157   \n",
       "3    lr       tvec       0.9872      0.9236   0.9362  128  16   8  162   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "1        0.9158             0.0796       0.8611       0.9706     0.8919   \n",
       "2        0.9132             0.0860       0.9028       0.9235     0.9181   \n",
       "3        0.9209             0.0764       0.8889       0.9529     0.9101   \n",
       "\n",
       "   roc_auc   params  \n",
       "0   0.9764  default  \n",
       "1   0.9753  default  \n",
       "2   0.9783  default  \n",
       "3   0.9826  default  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview scores in a dataframe\n",
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of our model is to help moderators identify whether a post is related to the Apple community and at the same time, filter out unrelated posts. Hence, an important metric would be accuracy, which is the rate of correctly predicting all classes. Since our data has slightly unbalanced classes, we can look at the balanced accuracy which is the average of recall obtained on each class `(sensitivity + specificity)/2` .\n",
    "\n",
    "Based on the tested models above, it appears that the Multinomial Naive Bayes model coupled with Count Vectorizer has the highest balanced accuracy rate. This model also seemed to generalise better based on the valid test score. Hence, we will select this model as our baseline model.\n",
    "\n",
    "<!-- \n",
    "\n",
    "Logistic Regression model coupled with the Tf-idf Vectorizer is generalising better, however the model is overfitting to the train data.\n",
    "\n",
    "In this case, we look at other metrics important to our model: Sensitivity and Specificity scores.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Since our model is to correctly predict whether or not a post belongs to either the Apple or Android subreddit, we would want to optimise both the sensitivity (or Recall/ True Positive) and the specificity (or True Negative) metrics.\n",
    "\n",
    "probability of correctly classifying your classes. A higher AUC represents a better mode!\n",
    "\n",
    "This model also has the least False negatives, Hence, we will tune the hyperparameters and see if the model improves. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters of the Multinomial Naive Bayes Model with CountVectorizer\n",
    "\n",
    "Using our baseline model, we will tune its hyperparameters using GridSearchCV to determine the combination to create a model that best generalizes to unseen data.\n",
    "\n",
    "We will be tuning the following parameters in our model:\n",
    "- CountVectorizer:\n",
    "    - tokenizer (using LemmaTokenizer/ StemTokenizer)      \n",
    "    - max_df (considers words with a max upper threshold of words or % of words)\n",
    "    - min_df (considers words with a min lower threshold of words or % of words)\n",
    "    - max_features (sets the maximum number of features in the model)\n",
    "    - ngram_range (captures n-word phrases)\n",
    "\n",
    "\n",
    "- MultinomialNB:\n",
    "    - alpha (magnitude of regularization)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to run pipe with vectorizer and estimator\n",
    "# also stores scores into dictionary\n",
    "\n",
    "def run_gs_pipe(pipe, X_train, X_test, y_train, y_test, df_scores, grid_params):\n",
    "    \n",
    "    #run gridsearch\n",
    "    gscv = GridSearchCV(pipe, grid_params, cv=5, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    #fit to grid\n",
    "    gscv.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Model = {gscv.best_estimator_.steps[1][0]} with {gscv.best_estimator_.steps[0][0]} \")\n",
    "    print(\"--------------------\\n\")\n",
    "    \n",
    "    #mean cross val score on train model\n",
    "    mean_cv_score = round(gscv.best_score_,4)\n",
    "    \n",
    "    #score our model on the training and test set\n",
    "    train_score = round(gscv.score(X_train, y_train),4)\n",
    "    test_score = round(gscv.score(X_test, y_test),4)\n",
    "    \n",
    "    #print model scores\n",
    "    print(f\"Cross val score on train model: {mean_cv_score}\")\n",
    "    print(f\"Accuracy score on train model: {train_score}\")\n",
    "    print(f\"Accuracy score on test model: {test_score}\")\n",
    "    print(f\"Best parameters: {gscv.best_params_}\")\n",
    "    \n",
    "    print(\"\\n--------------------\\n\")\n",
    "\n",
    "    \n",
    "    #generate predictions\n",
    "    y_pred = gscv.predict(X_test)\n",
    "    \n",
    "    #generate probabilities of predicting 1\n",
    "    y_proba = [i[1] for i in gscv.predict_proba(X_test)]\n",
    "    \n",
    "    #compute metrics\n",
    "    tn, fp, fn, tp, bal_accuracy, misclassification, specificity, sensitivity, precision, roc_auc = perf_metrics(\n",
    "        y_test, y_pred, y_proba)\n",
    "    \n",
    "    #store scores into dictionary\n",
    "    dict_scores = {'model': gscv.best_estimator_.steps[1][0],\n",
    "                 'vectorizer': gscv.best_estimator_.steps[0][0],\n",
    "                 'valid_train': train_score,\n",
    "                 'valid_test': test_score,\n",
    "                 'mean_cv': mean_cv_score,\n",
    "                 'tn': tn,\n",
    "                 'fp': fp,\n",
    "                 'fn': fn,\n",
    "                 'tp': tp,\n",
    "                 'bal_accuracy': bal_accuracy,\n",
    "                 'misclassification': misclassification,\n",
    "                 'specificity': specificity,\n",
    "                 'sensitivity': sensitivity,\n",
    "                 'precision': precision,\n",
    "                 'roc_auc' :roc_auc,\n",
    "                 'params': gscv.best_params_}\n",
    "    scores.append(dict_scores)\n",
    "    \n",
    "    return gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our pipeline\n",
    "pipe_cvec_nb = Pipeline([('cvec', CountVectorizer()),\n",
    "                         ('nb', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the CountVectorizer(tokenizer)\n",
    "In our previous section in Data Cleaning and EDA, we have cleaned our text data in 'title' to remove all non-letters and convert to lowercase letters for the same words to be categorised together. \n",
    "\n",
    "To further process our text data, we can use Lemmatizing or Stemming to shorten words so we can combine similar forms of the same word.\n",
    "\n",
    "When we \"lemmatize\" data, we take words and attempt to return their <i>lemma</i>, or the base/dictionary form of a word.\n",
    "\n",
    "When we \"stem\" data, we take words and attempt to return a base form of the word. It tends to be cruder than using lemmatization.\n",
    "\n",
    "Hence, we have created two class objects: `LemmaTokenizer` and `StemTokenizer` to insert into our hyperparameters tuning and determine if lemmatizing or stemming makes a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, title):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(title)]\n",
    "    \n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, title):\n",
    "        return [self.ps.stem(t) for t in word_tokenize(title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = nb with cvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9384\n",
      "Accuracy score on train model: 0.9862\n",
      "Accuracy score on test model: 0.9331\n",
      "Best parameters: {'cvec__tokenizer': None}\n",
      "\n",
      "--------------------\n",
      "\n",
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 7\n",
      "True Positives: 163\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9308\n",
      "Misclassification: 0.0669\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9588\n",
      "Precision: 0.9209\n",
      "ROC_AUC: 0.9764 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9489    0.9028    0.9253       144\n",
      "           1     0.9209    0.9588    0.9395       170\n",
      "\n",
      "    accuracy                         0.9331       314\n",
      "   macro avg     0.9349    0.9308    0.9324       314\n",
      "weighted avg     0.9337    0.9331    0.9330       314\n",
      "\n",
      "CPU times: user 169 ms, sys: 70.5 ms, total: 239 ms\n",
      "Wall time: 3.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create our first grid of parameters to tune\n",
    "param_1 = [{'cvec__tokenizer': [LemmaTokenizer(), StemTokenizer(), None]}]\n",
    "\n",
    "\n",
    "#run pipe\n",
    "gscv1 = run_gs_pipe(pipe_cvec_nb, X_train, X_test, y_train, y_test, dict_scores, param_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model works better without using lemmatization/stemming and would be a redundant feature, we shall exclude it in our grid of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the CountVectorizer(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Model = nb with cvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9394\n",
      "Accuracy score on train model: 0.9968\n",
      "Accuracy score on test model: 0.9299\n",
      "Best parameters: {'cvec__ngram_range': (1, 2)}\n",
      "\n",
      "--------------------\n",
      "\n",
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 8\n",
      "True Positives: 162\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9279\n",
      "Misclassification: 0.0701\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9529\n",
      "Precision: 0.9205\n",
      "ROC_AUC: 0.9782 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9420    0.9028    0.9220       144\n",
      "           1     0.9205    0.9529    0.9364       170\n",
      "\n",
      "    accuracy                         0.9299       314\n",
      "   macro avg     0.9312    0.9279    0.9292       314\n",
      "weighted avg     0.9303    0.9299    0.9298       314\n",
      "\n",
      "CPU times: user 120 ms, sys: 8.9 ms, total: 129 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create our second grid of parameters to tune\n",
    "param_2 = [{'cvec__ngram_range' : [(1,1), (1,2), (1,3)] # unigrams or bigrams or tri-grams\n",
    "           }]\n",
    "\n",
    "\n",
    "#run pipe\n",
    "gscv2 = run_gs_pipe(pipe_cvec_nb, X_train, X_test, y_train, y_test, dict_scores, param_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>124</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>{'cvec__tokenizer': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>{'cvec__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "1    nb       tvec       0.9894      0.9204   0.9256  124  20   5  165   \n",
       "2    lr       cvec       0.9968      0.9140   0.9235  130  14  13  157   \n",
       "3    lr       tvec       0.9872      0.9236   0.9362  128  16   8  162   \n",
       "4    nb       cvec       0.9862      0.9331   0.9384  130  14   7  163   \n",
       "5    nb       cvec       0.9968      0.9299   0.9394  130  14   8  162   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "1        0.9158             0.0796       0.8611       0.9706     0.8919   \n",
       "2        0.9132             0.0860       0.9028       0.9235     0.9181   \n",
       "3        0.9209             0.0764       0.8889       0.9529     0.9101   \n",
       "4        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "5        0.9279             0.0701       0.9028       0.9529     0.9205   \n",
       "\n",
       "   roc_auc                         params  \n",
       "0   0.9764                        default  \n",
       "1   0.9753                        default  \n",
       "2   0.9783                        default  \n",
       "3   0.9826                        default  \n",
       "4   0.9764      {'cvec__tokenizer': None}  \n",
       "5   0.9782  {'cvec__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the gridsearch has identified best params to be n-grams of (1,2). As the 'valid_train' score seemed to increase, the 'valid_test' score did not increase. Hence, the model is not generalising better. In addition, there is an increase in misclassification rate which is not a favourable outcome. Hence, we wil set n-gram to the default parameter for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = nb with cvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9373\n",
      "Accuracy score on train model: 0.9819\n",
      "Accuracy score on test model: 0.9331\n",
      "Best parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 2100, 'cvec__min_df': 1}\n",
      "\n",
      "--------------------\n",
      "\n",
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 7\n",
      "True Positives: 163\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9308\n",
      "Misclassification: 0.0669\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9588\n",
      "Precision: 0.9209\n",
      "ROC_AUC: 0.9761 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9489    0.9028    0.9253       144\n",
      "           1     0.9209    0.9588    0.9395       170\n",
      "\n",
      "    accuracy                         0.9331       314\n",
      "   macro avg     0.9349    0.9308    0.9324       314\n",
      "weighted avg     0.9337    0.9331    0.9330       314\n",
      "\n",
      "CPU times: user 214 ms, sys: 14.4 ms, total: 229 ms\n",
      "Wall time: 283 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  60 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create our third grid of parameters to tune\n",
    "param_3 = [{'cvec__max_df': [0.9, 1.0],\n",
    "            'cvec__min_df': [1 , 2],\n",
    "            'cvec__max_features': [1500, 2000, 2100],\n",
    "           }]\n",
    "\n",
    "\n",
    "#run pipe\n",
    "gscv3 = run_gs_pipe(pipe_cvec_nb, X_train, X_test, y_train, y_test, dict_scores, param_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>124</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>{'cvec__tokenizer': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>{'cvec__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "1    nb       tvec       0.9894      0.9204   0.9256  124  20   5  165   \n",
       "2    lr       cvec       0.9968      0.9140   0.9235  130  14  13  157   \n",
       "3    lr       tvec       0.9872      0.9236   0.9362  128  16   8  162   \n",
       "4    nb       cvec       0.9862      0.9331   0.9384  130  14   7  163   \n",
       "5    nb       cvec       0.9968      0.9299   0.9394  130  14   8  162   \n",
       "6    nb       cvec       0.9819      0.9331   0.9373  130  14   7  163   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "1        0.9158             0.0796       0.8611       0.9706     0.8919   \n",
       "2        0.9132             0.0860       0.9028       0.9235     0.9181   \n",
       "3        0.9209             0.0764       0.8889       0.9529     0.9101   \n",
       "4        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "5        0.9279             0.0701       0.9028       0.9529     0.9205   \n",
       "6        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "\n",
       "   roc_auc                                             params  \n",
       "0   0.9764                                            default  \n",
       "1   0.9753                                            default  \n",
       "2   0.9783                                            default  \n",
       "3   0.9826                                            default  \n",
       "4   0.9764                          {'cvec__tokenizer': None}  \n",
       "5   0.9782                      {'cvec__ngram_range': (1, 2)}  \n",
       "6   0.9761  {'cvec__max_df': 0.9, 'cvec__max_features': 21...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score did not seem to improve from its baseline model, hence we will set CountVectorizer to its default hyperparameters. We will now tune hyperparameters for the Multinomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3200 tasks      | elapsed:    9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = nb with cvec \n",
      "--------------------\n",
      "\n",
      "Cross val score on train model: 0.9426\n",
      "Accuracy score on train model: 0.9851\n",
      "Accuracy score on test model: 0.9363\n",
      "Best parameters: {'nb__alpha': 1.303512244681509}\n",
      "\n",
      "--------------------\n",
      "\n",
      "True Negatives: 130\n",
      "False Positives: 14\n",
      "False Negatives: 6\n",
      "True Positives: 164\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9337\n",
      "Misclassification: 0.0637\n",
      "Specificity: 0.9028\n",
      "Sensitivity: 0.9647\n",
      "Precision: 0.9213\n",
      "ROC_AUC: 0.9771 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9559    0.9028    0.9286       144\n",
      "           1     0.9213    0.9647    0.9425       170\n",
      "\n",
      "    accuracy                         0.9363       314\n",
      "   macro avg     0.9386    0.9337    0.9356       314\n",
      "weighted avg     0.9372    0.9363    0.9361       314\n",
      "\n",
      "CPU times: user 6.93 s, sys: 180 ms, total: 7.11 s\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   15.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create our fourth grid of parameters to tune\n",
    "param_4 = [{'nb__alpha' : np.logspace(0,5,1000)\n",
    "           }]\n",
    "\n",
    "\n",
    "#run pipe\n",
    "gscv4 = run_gs_pipe(pipe_cvec_nb, X_train, X_test, y_train, y_test, dict_scores, param_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>valid_train</th>\n",
       "      <th>valid_test</th>\n",
       "      <th>mean_cv</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>bal_accuracy</th>\n",
       "      <th>misclassification</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>124</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>{'cvec__tokenizer': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>{'cvec__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>{'cvec__max_df': 0.9, 'cvec__max_features': 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>{'nb__alpha': 1.303512244681509}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model vectorizer  valid_train  valid_test  mean_cv   tn  fp  fn   tp  \\\n",
       "0    nb       cvec       0.9862      0.9331   0.9373  130  14   7  163   \n",
       "1    nb       tvec       0.9894      0.9204   0.9256  124  20   5  165   \n",
       "2    lr       cvec       0.9968      0.9140   0.9235  130  14  13  157   \n",
       "3    lr       tvec       0.9872      0.9236   0.9362  128  16   8  162   \n",
       "4    nb       cvec       0.9862      0.9331   0.9384  130  14   7  163   \n",
       "5    nb       cvec       0.9968      0.9299   0.9394  130  14   8  162   \n",
       "6    nb       cvec       0.9819      0.9331   0.9373  130  14   7  163   \n",
       "7    nb       cvec       0.9851      0.9363   0.9426  130  14   6  164   \n",
       "\n",
       "   bal_accuracy  misclassification  specificity  sensitivity  precision  \\\n",
       "0        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "1        0.9158             0.0796       0.8611       0.9706     0.8919   \n",
       "2        0.9132             0.0860       0.9028       0.9235     0.9181   \n",
       "3        0.9209             0.0764       0.8889       0.9529     0.9101   \n",
       "4        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "5        0.9279             0.0701       0.9028       0.9529     0.9205   \n",
       "6        0.9308             0.0669       0.9028       0.9588     0.9209   \n",
       "7        0.9337             0.0637       0.9028       0.9647     0.9213   \n",
       "\n",
       "   roc_auc                                             params  \n",
       "0   0.9764                                            default  \n",
       "1   0.9753                                            default  \n",
       "2   0.9783                                            default  \n",
       "3   0.9826                                            default  \n",
       "4   0.9764                          {'cvec__tokenizer': None}  \n",
       "5   0.9782                      {'cvec__ngram_range': (1, 2)}  \n",
       "6   0.9761  {'cvec__max_df': 0.9, 'cvec__max_features': 21...  \n",
       "7   0.9771                   {'nb__alpha': 1.303512244681509}  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparamters tuning the additive smoothing parameter, the performance metrics seemed to be slightly better.\n",
    "Hence, this model will be selected as our production model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export scores to csv:\n",
    "pd.DataFrame(data=scores).to_csv('../datasets/scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gscv4.predict(test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 132\n",
      "False Positives: 14\n",
      "False Negatives: 10\n",
      "True Positives: 158\n",
      "\n",
      "Performance metrics\n",
      "--------------------\n",
      "Balanced Accuracy: 0.9223\n",
      "Misclassification: 0.0764\n",
      "Specificity: 0.9041\n",
      "Sensitivity: 0.9405\n",
      "Precision: 0.9186\n",
      "ROC_AUC: 0.98 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.9041    0.9167       146\n",
      "           1     0.9186    0.9405    0.9294       168\n",
      "\n",
      "    accuracy                         0.9236       314\n",
      "   macro avg     0.9241    0.9223    0.9230       314\n",
      "weighted avg     0.9237    0.9236    0.9235       314\n",
      "\n",
      "Accuracy: 0.9235668789808917\n"
     ]
    }
   ],
   "source": [
    "pred_proba = [i[1] for i in gscv4.predict_proba(test_title)]\n",
    "    \n",
    "#compute metrics\n",
    "tn, fp, fn, tp, bal_accuracy, misclassification, specificity, sensitivity, precision, roc_auc = perf_metrics(\n",
    "    test_subreddit, predictions, pred_proba)\n",
    "print(f\"Accuracy: {gscv4.score(test_title, test_subreddit)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store production model scores into dictionary\n",
    "prod_scores = {'model': gscv4.best_estimator_.steps[1][0],\n",
    "             'vectorizer': gscv4.best_estimator_.steps[0][0],\n",
    "             'tn': tn,\n",
    "             'fp': fp,\n",
    "             'fn': fn,\n",
    "             'tp': tp,\n",
    "             'mean_cv': gscv4.best_score_,\n",
    "             'accuracy': gscv4.score(test_title, test_subreddit),\n",
    "             'bal_accuracy': bal_accuracy,\n",
    "             'misclassification': misclassification,\n",
    "             'specificity': specificity,\n",
    "             'sensitivity': sensitivity,\n",
    "             'precision': precision,\n",
    "             'roc_auc' :roc_auc,\n",
    "             'params': gscv4.best_params_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export production scores on unseen to csv:\n",
    "pd.DataFrame(data=prod_scores).to_csv('../datasets/prod_score.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "    <div class=\"right\"> >>> <b>Next: </b>\n",
    "        <a href=\"./04_conclusion_and_recommendation.ipynb\">Conclusion and Recommendations</a>\n",
    "    </div>\n",
    "    </div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to top](#top)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
